{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fe10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c1ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH_TO_DATA = \"./fer2013.csv\" # Change path for the dataset\n",
    "\n",
    "\n",
    "def capture_and_process_image():\n",
    "    # Open the device's camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Capture an image\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Use a pre-trained facial landmark detector to identify the user's eyes\n",
    "    eyes = detect_eyes(frame)\n",
    "\n",
    "    # Crop the image to only include the user's eyes\n",
    "    eyes = crop_to_eyes(frame, eyes)\n",
    "\n",
    "    # Resize the image to 32x32 pixels\n",
    "    eyes = cv2.resize(eyes, (32, 32))\n",
    "\n",
    "    # Convert the image to floating-point values\n",
    "    eyes = eyes.astype('float32')\n",
    "\n",
    "    # Return the preprocessed image\n",
    "    return eyes\n",
    "\n",
    "# Define a map from emotion labels to numeric values\n",
    "emotion_map = [\n",
    "    'anger',\n",
    "    'disgust',\n",
    "    'fear',\n",
    "    'happiness',\n",
    "    'sadness',\n",
    "    'surprise',\n",
    "    'neutral',\n",
    "]\n",
    "\n",
    "def load_dataset():\n",
    "    # Load the fer2013 dataset from a CSV file\n",
    "    data = pd.read_csv(PATH_TO_DATA)\n",
    "\n",
    "    # Separate the images and labels\n",
    "\n",
    "    y = data['emotion']\n",
    "    # Convert the images to 32x32 pixel arrays\n",
    "    X = np.array([np.array(image.split()) for image in data['pixels']])\n",
    "\n",
    "    # Convert the labels to numeric values\n",
    "    # print(y)\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Return the training and test sets\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Load the training and test datasets\n",
    "X_train, y_train, X_test, y_test = load_dataset()\n",
    "\n",
    "# Create an SVM classifier\n",
    "#classifier = sklearn.svm.SVC()\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear', C=1, gamma=1)\n",
    "\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy)\n",
    "\n",
    "# Continuously capture and classify images\n",
    "while True:\n",
    "    # Capture and preprocess an image\n",
    "    image = capture_and_process_image()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7405e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
